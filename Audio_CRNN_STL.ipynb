{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def STL_AUC(model,SDG,y_true):\n",
    "    Skip_Tag = []\n",
    "        \n",
    "    y_pred = model.predict_generator(SDG) # (#data x 50()) \n",
    "    y_pred_out = y_pred.copy()\n",
    "    #print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "    for i in range(len(y_pred)):\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if y_pred[i][j] >= 0.5 : \n",
    "                y_pred[i][j] = 1\n",
    "            else:\n",
    "                y_pred[i][j] = 0\n",
    "    \n",
    "    #print(y_pred.shape,y_true.shape)\n",
    "    \n",
    "    try:\n",
    "        AUC_this_epoch = roc_auc_score(y_true ,y_pred)\n",
    "    except:\n",
    "        AUC_this_epoch = 0\n",
    "    \n",
    "    \n",
    "    AUC_List = []\n",
    "    y_pred_T = y_pred.T\n",
    "    y_true_T = y_true.T\n",
    "    \n",
    "    for i in range(50):\n",
    "        \n",
    "        try:\n",
    "            AUC_List.append( roc_auc_score(y_true_T[i] ,y_pred_T[i]))\n",
    "        except:\n",
    "            AUC_List.append(0)\n",
    "    return AUC_this_epoch,AUC_List,y_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read Data Base\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "uri = \"mongodb://localhost:27017/database\" #mongodb://<user_name>:<user_password>@ds<xxxxxx>.mlab.com:<xxxxx>/<database_name>\n",
    "conn =  MongoClient(host='localhost', port=27017, connect=False)\n",
    "db = conn.PaperData\n",
    "Spectrogram_Collection  =  db.get_collection('MSD_mel1366')\n",
    "#LineCNN_Collection  =  db.get_collection('LineCNNMatrix_100thTag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58487"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spectrogram_Collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Filename_text'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spectrogram_Collection.create_index([(\"Filename\",\"text\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio Para\n",
    "_mel_scale = 96\n",
    "_time_len = 1366\n",
    "_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_num_Tags = 50\n",
    "_epchos = 200\n",
    "_stopEpcho = 10\n",
    "_batchSize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import codecs\n",
    "import numpy as np\n",
    "def read_json(filename):\n",
    "    with codecs.open(filename,'r',encoding = 'utf8') as infile:\n",
    "        return np.array(json.load(infile))\n",
    "    \n",
    "x_train = read_json('New_x_train.json')\n",
    "y_train = read_json('New_y_train.json')\n",
    "x_test = read_json('New_x_test.json')\n",
    "y_test = read_json('New_y_test.json')\n",
    "x_val = read_json('New_x_val.json')\n",
    "y_val = read_json('New_y_val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8486"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CL_1_kernal = 169\n",
    "_CL_2_kernal = 339\n",
    "_CL_3_kernal = 339\n",
    "_CL_4_kernal = 339\n",
    "_RNN_1_kernal = 169\n",
    "_RNN_2_kernal = 169\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectrogram_Input = Input(name= 'AudioInput',shape=(_mel_scale, _time_len, _channels)) #(None(1), 96, 1292, 1)\n",
    "CL_1 = Conv2D(_CL_1_kernal, kernel_size=(3, 3),padding='same', name = \"CL_1\")(Spectrogram_Input) #(None, 96, 1292, 128) \n",
    "BN_1 = BatchNormalization()(CL_1)\n",
    "AL_1 = ELU()(BN_1)\n",
    "MP_1 = MaxPool2D(pool_size= (2,2), name = \"MPL_1\")(AL_1) #(None, 48, 323, 128)\n",
    "DP_1 = Dropout(0.1)(MP_1)\n",
    "\n",
    "CL_2 = Conv2D(_CL_2_kernal, kernel_size=(3, 3),padding='same', name = \"CL_2\")(DP_1) # (None, 48, 323, 384) \n",
    "BN_2 = BatchNormalization()(CL_2)\n",
    "AL_2 = ELU()(BN_2)\n",
    "MP_2 = MaxPool2D(pool_size= (3,3), name = \"MPL_2\")(AL_2) # (None, 12, 64, 384) \n",
    "DP_2 = Dropout(0.1)(MP_2)\n",
    "\n",
    "CL_3 = Conv2D(_CL_3_kernal, kernel_size=(3, 3),padding='same', name = \"CL_3\")(DP_2) #(None, 12, 64, 768) \n",
    "BN_3 = BatchNormalization()(CL_3)\n",
    "AL_3 = ELU()(BN_3)\n",
    "MP_3 = MaxPool2D(pool_size= (4,4), name = \"MPL_3\")(AL_3) #(None, 4, 8, 768)\n",
    "DP_3 = Dropout(0.1)(MP_3)\n",
    "\n",
    "CL_4 = Conv2D(_CL_4_kernal, kernel_size=(3, 3),padding='same', name = \"CL_4\")(DP_3) #(None, 4, 8, 2048) \n",
    "BN_4 = BatchNormalization()(CL_4)\n",
    "AL_4 = ELU()(BN_4)\n",
    "MP_4 = MaxPool2D(pool_size= (4,4), name = \"MPL_4\")(AL_4)#(None, 1, 1, 2048) \n",
    "DP_4 = Dropout(0.1)(MP_4)\n",
    "\n",
    "AR = Permute((3,2,1))(DP_4)\n",
    "RS = Reshape((14, _CL_2_kernal))(DP_4)\n",
    "\n",
    "GRU_1 = GRU(_RNN_1_kernal, return_sequences=True, name='GRU_1')(RS)\n",
    "GRU_2 = GRU(_RNN_2_kernal, return_sequences=False, name='GRU_2')(GRU_1)\n",
    "\n",
    "#pseudo-model for sheck summary\n",
    "Softmax = Dense(_num_Tags, kernel_initializer='normal',activation='sigmoid')(GRU_2)\n",
    "Audio_model = Model(inputs=Spectrogram_Input, outputs=Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "AudioInput (InputLayer)      (None, 96, 1366, 1)       0         \n",
      "_________________________________________________________________\n",
      "CL_1 (Conv2D)                (None, 96, 1366, 169)     1690      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1366, 169)     676       \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 96, 1366, 169)     0         \n",
      "_________________________________________________________________\n",
      "MPL_1 (MaxPooling2D)         (None, 48, 683, 169)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 683, 169)      0         \n",
      "_________________________________________________________________\n",
      "CL_2 (Conv2D)                (None, 48, 683, 339)      515958    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 683, 339)      1356      \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 48, 683, 339)      0         \n",
      "_________________________________________________________________\n",
      "MPL_2 (MaxPooling2D)         (None, 16, 227, 339)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 227, 339)      0         \n",
      "_________________________________________________________________\n",
      "CL_3 (Conv2D)                (None, 16, 227, 339)      1034628   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 227, 339)      1356      \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 16, 227, 339)      0         \n",
      "_________________________________________________________________\n",
      "MPL_3 (MaxPooling2D)         (None, 4, 56, 339)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 56, 339)        0         \n",
      "_________________________________________________________________\n",
      "CL_4 (Conv2D)                (None, 4, 56, 339)        1034628   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 56, 339)        1356      \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 4, 56, 339)        0         \n",
      "_________________________________________________________________\n",
      "MPL_4 (MaxPooling2D)         (None, 1, 14, 339)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 14, 339)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 14, 339)           0         \n",
      "_________________________________________________________________\n",
      "GRU_1 (GRU)                  (None, 14, 169)           258063    \n",
      "_________________________________________________________________\n",
      "GRU_2 (GRU)                  (None, 169)               171873    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                8500      \n",
      "=================================================================\n",
      "Total params: 3,030,084\n",
      "Trainable params: 3,027,712\n",
      "Non-trainable params: 2,372\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Audio_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "import json\n",
    "import codecs\n",
    "class AudioDataGenerator(Sequence):\n",
    "    #batch size can only be 1\n",
    "    def __init__(self, text_filenames, labels,batch_size):\n",
    "        self.text_filenames, self.labels = text_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.text_filenames)/ (self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Here, you have to imprement what the data looks like in each epcho\n",
    "        filename_List =  self.text_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        #Text_batch_x = [] \n",
    "        Audio_batch_x = []\n",
    "        for filename in filename_List:  \n",
    "            Audio_x = np.array(Spectrogram_Collection.find_one({\"Filename\":filename})['Spectrogram']).reshape((_mel_scale,_time_len,_channels))\n",
    "            Audio_batch_x.append(Audio_x)\n",
    "        y_List = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return np.array(Audio_batch_x), np.array(y_List)\n",
    "    def getitem(self, idx):\n",
    "        #Here, you have to imprement what the data looks like in each epcho\n",
    "        \n",
    "        return self.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADG_train = AudioDataGenerator(x_train, y_train, _batchSize)\n",
    "ADG_test = AudioDataGenerator(x_test[:8480], y_test[:8480], _batchSize) #skip 6 song while training\n",
    "ADG_val = AudioDataGenerator(x_val, y_val, _batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This callback is for binary softmax \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class AUC_callback(Callback):\n",
    "    def __init__(self,y_true,SDG,batchsize):\n",
    "        self.y_true = y_true\n",
    "        self.SDG = SDG\n",
    "        self.step = (len(y_true) // _batchSize)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Skip_Tag = []\n",
    "        \n",
    "        y_pred = self.model.predict_generator(generator = self.SDG,\n",
    "                                         steps = self.step,\n",
    "                                        workers = 12,\n",
    "                                        use_multiprocessing=True,) # (#data x 50()) \n",
    "        y_pred_out = y_pred.copy()\n",
    "    #print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "        for i in range(len(y_pred)):\n",
    "            for j in range(len(y_pred[i])):\n",
    "                if y_pred[i][j] >= 0.5 : \n",
    "                    y_pred[i][j] = 1\n",
    "                else:\n",
    "                    y_pred[i][j] = 0\n",
    "        try:\n",
    "            AUC_this_epoch = roc_auc_score(self.y_true ,y_pred)\n",
    "        except Exception as e:\n",
    "            AUC_this_epoch = 0\n",
    "            print(e)\n",
    "    \n",
    "        AUC_List = []\n",
    "        y_pred_T = y_pred.T\n",
    "        y_true_T = self.y_true .T\n",
    "    \n",
    "        for i in range(50):\n",
    "            try:\n",
    "                AUC_List.append( roc_auc_score(y_true_T[i] ,y_pred_T[i]))\n",
    "            except:\n",
    "                AUC_List.append(0)\n",
    "\n",
    "        logs['AUC_test'] = AUC_this_epoch\n",
    "        \n",
    "        logs['AUC_List'] = AUC_List\n",
    "        \n",
    "        print('AUC_test: %s '% (str(round(AUC_this_epoch,5))))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This callback is for binary softmax \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class AUC_callback_TF(Callback):\n",
    "    def __init__(self,y_true,SDG,batchsize):\n",
    "        self.y_true = y_true\n",
    "        self.SDG = SDG\n",
    "        self.step = (len(y_true) // _batchSize)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Skip_Tag = []\n",
    "        \n",
    "        y_pred = self.model.predict_generator(generator = self.SDG,\n",
    "                                         steps = self.step,\n",
    "                                        workers = 12,\n",
    "                                        use_multiprocessing=True,) # (#data x 50()) \n",
    "        y_pred_out = y_pred.copy()\n",
    "    #print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "        for i in range(len(y_pred)):\n",
    "            for j in range(len(y_pred[i])):\n",
    "                if y_pred[i][j] >= 0.5 : \n",
    "                    y_pred[i][j] = 1\n",
    "                else:\n",
    "                    y_pred[i][j] = 0\n",
    "        try:\n",
    "            auc, update_op = tf.metrics.auc(self.y_true ,K.round(y_pred))\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.local_variables_initializer())\n",
    "                AUC_this_epoch= sess.run([auc, update_op])[0]\n",
    "        except Exception as e:\n",
    "            AUC_this_epoch = 0\n",
    "            print(e)\n",
    "    \n",
    "        AUC_List = []\n",
    "        y_pred_T = y_pred.T\n",
    "        y_true_T = self.y_true.T\n",
    "    \n",
    "        for i in range(50):\n",
    "            try:\n",
    "                auc, update_op = tf.metrics.auc(y_true_T[i] ,K.round(y_pred_T[i]))\n",
    "                with tf.Session() as sess:\n",
    "                    sess.run(tf.local_variables_initializer())\n",
    "                    AUC_List.append(sess.run([auc, update_op])[0])\n",
    "            except Exception as e:\n",
    "                AUC_List.append(0)\n",
    "                print(e)\n",
    "        logs['AUC_test'] = AUC_this_epoch\n",
    "        \n",
    "        logs['AUC_List'] = AUC_List\n",
    "        \n",
    "        print('AUC_test: %s '% (str(round(AUC_this_epoch,5))))\n",
    "        \n",
    "        \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_AUC = AUC_callback_TF(y_test[:8480],ADG_test,_batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc: [0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "auc, update_op = tf.metrics.auc(np.array([[0,0,1],[1,0,1],[0,1,0]]), np.array([[0,0,0],[0,0,0],[0,0,0]]))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    print(\"tf auc: {}\".format(sess.run([auc, update_op])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_auc',mode='max', patience=_stopEpcho, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import time\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.epoch_time_end = time.time()\n",
    "        self.times.append(self.epoch_time_end - self.epoch_time_start)\n",
    "        logs['Timer'] = self.epoch_time_end - self.epoch_time_start\n",
    "time_callback = TimeHistory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_metrics\n",
    "precision = keras_metrics.precision(label = 1)\n",
    "recall = keras_metrics.recall(label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.quora.com/Why-does-my-convolutional-neural-network-always-produce-the-same-outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"TVT_Audio_CRNN_best.hdf5\",monitor='val_auc',mode = 'max', verbose=1, save_best_only=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true,  K.round(y_pred))[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples = len(x_train)\n",
    "num_validation_samples = len(x_val)\n",
    "num_test_samples =  len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "#THis may be the final version of CRNN audio !!!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.utils import multi_gpu_model\n",
    "parallel_model = multi_gpu_model(Audio_model, gpus=2)\n",
    "parallel_model.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer='adam',\n",
    "                      metrics=[auc])\n",
    "History = parallel_model.fit_generator(\n",
    "                    generator= ADG_train,\n",
    "                    steps_per_epoch=(num_training_samples // _batchSize),\n",
    "                    epochs= 100,\n",
    "                    verbose=1,\n",
    "                    validation_data= ADG_val,\n",
    "                    validation_steps=(num_validation_samples // _batchSize),\n",
    "                    workers=12, use_multiprocessing=True,\n",
    "                    callbacks = [Test_AUC,early_stopping,time_callback, checkpointer]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opti = Adam(lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "parallel_model = multi_gpu_model(Audio_model, gpus=2)\n",
    "parallel_model.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer= opti,\n",
    "                      metrics=[auc])\n",
    "parallel_model.load_weights('Audio_CRNN_RE_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1060/1060 [==============================] - 652s 615ms/step - loss: 0.1311 - auc: 0.8346 - val_loss: 0.3873 - val_auc: 0.8045\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.80448, saving model to Audio_CRNN_RE_best.hdf5\n",
      "Epoch 2/100\n",
      "1060/1060 [==============================] - 655s 618ms/step - loss: 0.1370 - auc: 0.7952 - val_loss: 0.3684 - val_auc: 0.7906\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.80448\n",
      "Epoch 3/100\n",
      "1060/1060 [==============================] - 659s 621ms/step - loss: 0.1366 - auc: 0.7881 - val_loss: 0.3817 - val_auc: 0.7858\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.80448\n",
      "Epoch 4/100\n",
      "1060/1060 [==============================] - 662s 624ms/step - loss: 0.1367 - auc: 0.7845 - val_loss: 0.3637 - val_auc: 0.7833\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.80448\n",
      "Epoch 5/100\n",
      "1060/1060 [==============================] - 659s 622ms/step - loss: 0.1368 - auc: 0.7828 - val_loss: 0.3635 - val_auc: 0.7819\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.80448\n",
      "Epoch 6/100\n",
      "1060/1060 [==============================] - 660s 622ms/step - loss: 0.1355 - auc: 0.7815 - val_loss: 0.3685 - val_auc: 0.7811\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.80448\n",
      "Epoch 7/100\n",
      "1060/1060 [==============================] - 663s 625ms/step - loss: 0.1355 - auc: 0.7809 - val_loss: 0.3641 - val_auc: 0.7806\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.80448\n",
      "Epoch 8/100\n",
      "1060/1060 [==============================] - 663s 626ms/step - loss: 0.1358 - auc: 0.7805 - val_loss: 0.3592 - val_auc: 0.7802\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.80448\n",
      "Epoch 9/100\n",
      "1060/1060 [==============================] - 661s 624ms/step - loss: 0.1347 - auc: 0.7802 - val_loss: 0.3931 - val_auc: 0.7797\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.80448\n",
      "Epoch 10/100\n",
      "1060/1060 [==============================] - 663s 626ms/step - loss: 0.1331 - auc: 0.7795 - val_loss: 0.3706 - val_auc: 0.7793\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.80448\n",
      "Epoch 11/100\n",
      "1060/1060 [==============================] - 662s 625ms/step - loss: 0.1328 - auc: 0.7793 - val_loss: 0.3808 - val_auc: 0.7791\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.80448\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "#keep  training  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "History = parallel_model.fit_generator(\n",
    "                    generator= ADG_train,\n",
    "                    steps_per_epoch=(num_training_samples // _batchSize),\n",
    "                    epochs= 100,\n",
    "                    verbose=1,\n",
    "                    validation_data= ADG_test,\n",
    "                    validation_steps=(num_validation_samples // _batchSize),\n",
    "                    workers=12, use_multiprocessing=True,\n",
    "                    callbacks = [ early_stopping,time_callback, checkpointer]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "parallel_model = multi_gpu_model(Audio_model, gpus=2)\n",
    "\n",
    "parallel_model.load_weights('Audio_CRNN_RE_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = parallel_model.predict_generator(ADG_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_out = y_pred.copy()\n",
    "#print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if y_pred[i][j] >= 0.5 : \n",
    "            y_pred[i][j] = 1\n",
    "        else:\n",
    "            y_pred[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc: [0.6297745, 0.6297745]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    auc, update_op = tf.metrics.auc(y_test ,K.round(y_pred))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        print(\"tf auc: {}\".format(sess.run([auc, update_op])))\n",
    "except:\n",
    "    AUC_this_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc: [0.6534231, 0.6534231]\n",
      "tf auc: [0.6241743, 0.6241743]\n",
      "tf auc: [0.6459072, 0.6459072]\n",
      "tf auc: [0.6728258, 0.6728258]\n",
      "tf auc: [0.7067504, 0.7067504]\n",
      "tf auc: [0.72282284, 0.72282284]\n",
      "tf auc: [0.5207818, 0.5207818]\n",
      "tf auc: [0.65525174, 0.65525174]\n",
      "tf auc: [0.53992045, 0.53992045]\n",
      "tf auc: [0.5619868, 0.5619868]\n",
      "tf auc: [0.5573579, 0.5573579]\n",
      "tf auc: [0.5909789, 0.5909789]\n",
      "tf auc: [0.8613825, 0.8613825]\n",
      "tf auc: [0.543588, 0.543588]\n",
      "tf auc: [0.5474859, 0.5474859]\n",
      "tf auc: [0.54947364, 0.54947364]\n",
      "tf auc: [0.6174882, 0.6174882]\n",
      "tf auc: [0.6478371, 0.6478371]\n",
      "tf auc: [0.54673547, 0.54673547]\n",
      "tf auc: [0.64941263, 0.64941263]\n",
      "tf auc: [0.6622169, 0.6622169]\n",
      "tf auc: [0.52822673, 0.52822673]\n",
      "tf auc: [0.5522953, 0.5522953]\n",
      "tf auc: [0.5113181, 0.5113181]\n",
      "tf auc: [0.5058585, 0.5058585]\n",
      "tf auc: [0.74202037, 0.74202037]\n",
      "tf auc: [0.58788806, 0.58788806]\n",
      "tf auc: [0.5220632, 0.5220632]\n",
      "tf auc: [0.6729144, 0.6729144]\n",
      "tf auc: [0.6641269, 0.6641269]\n",
      "tf auc: [0.5006593, 0.5006593]\n",
      "tf auc: [0.5303705, 0.5303705]\n",
      "tf auc: [0.6105633, 0.6105633]\n",
      "tf auc: [0.5239022, 0.5239022]\n",
      "tf auc: [0.52161187, 0.52161187]\n",
      "tf auc: [0.71172667, 0.71172667]\n",
      "tf auc: [0.56789607, 0.56789607]\n",
      "tf auc: [0.51988953, 0.51988953]\n",
      "tf auc: [0.7504759, 0.7504759]\n",
      "tf auc: [0.51376504, 0.51376504]\n",
      "tf auc: [0.5197171, 0.5197171]\n",
      "tf auc: [0.5161488, 0.5161488]\n",
      "tf auc: [0.576519, 0.576519]\n",
      "tf auc: [0.5291605, 0.5291605]\n",
      "tf auc: [0.5817317, 0.5817317]\n",
      "tf auc: [0.5064391, 0.5064391]\n",
      "tf auc: [0.7051998, 0.7051998]\n",
      "tf auc: [0.50595975, 0.50595975]\n",
      "tf auc: [0.5125271, 0.5125271]\n",
      "tf auc: [0.51663274, 0.51663274]\n"
     ]
    }
   ],
   "source": [
    "AUC_List = []\n",
    "y_pred_T = y_pred.T\n",
    "y_test_T = y_test.T\n",
    "    \n",
    "for i in range(50):\n",
    "        \n",
    "    try:\n",
    "        auc, update_op = tf.metrics.auc(y_test_T[i] ,K.round(y_pred_T[i]))\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            print(\"tf auc: {}\".format(sess.run([auc, update_op])))\n",
    "        \n",
    "        \n",
    "        AUC_List.append(auc)\n",
    "        \n",
    "    except:\n",
    "        AUC_List.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#69epcho try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = parallel_model.predict_generator(ADG_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_out = y_pred.copy()\n",
    "#print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if y_pred[i][j] >= 0.5 : \n",
    "            y_pred[i][j] = 1\n",
    "        else:\n",
    "            y_pred[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc: [0.63480747, 0.63480747]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    auc, update_op = tf.metrics.auc(y_test ,K.round(y_pred))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        print(\"tf auc: {}\".format(sess.run([auc, update_op])))\n",
    "except:\n",
    "    AUC_this_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc: [0.64767826, 0.64767826]\n",
      "tf auc: [0.6292925, 0.6292925]\n",
      "tf auc: [0.63888514, 0.63888514]\n",
      "tf auc: [0.7164605, 0.7164605]\n",
      "tf auc: [0.6813197, 0.6813197]\n",
      "tf auc: [0.73677444, 0.73677444]\n",
      "tf auc: [0.52957714, 0.52957714]\n",
      "tf auc: [0.63481236, 0.63481236]\n",
      "tf auc: [0.5514498, 0.5514498]\n",
      "tf auc: [0.59014535, 0.59014535]\n",
      "tf auc: [0.54988223, 0.54988223]\n",
      "tf auc: [0.62775433, 0.62775433]\n",
      "tf auc: [0.8274743, 0.8274743]\n",
      "tf auc: [0.5794283, 0.5794283]\n",
      "tf auc: [0.54832786, 0.54832786]\n",
      "tf auc: [0.52247435, 0.52247435]\n",
      "tf auc: [0.6200569, 0.6200569]\n",
      "tf auc: [0.72143865, 0.72143865]\n",
      "tf auc: [0.5867646, 0.5867646]\n",
      "tf auc: [0.6463666, 0.6463666]\n",
      "tf auc: [0.6057831, 0.6057831]\n",
      "tf auc: [0.5394561, 0.5394561]\n",
      "tf auc: [0.54549307, 0.54549307]\n",
      "tf auc: [0.512792, 0.512792]\n",
      "tf auc: [0.50711316, 0.50711316]\n",
      "tf auc: [0.7794095, 0.7794095]\n",
      "tf auc: [0.6600449, 0.6600449]\n",
      "tf auc: [0.5128818, 0.5128818]\n",
      "tf auc: [0.6955229, 0.6955229]\n",
      "tf auc: [0.6355979, 0.6355979]\n",
      "tf auc: [0.5045329, 0.5045329]\n",
      "tf auc: [0.52034545, 0.52034545]\n",
      "tf auc: [0.6288952, 0.6288952]\n",
      "tf auc: [0.5478566, 0.5478566]\n",
      "tf auc: [0.52008796, 0.52008796]\n",
      "tf auc: [0.7689491, 0.7689491]\n",
      "tf auc: [0.58673126, 0.58673126]\n",
      "tf auc: [0.5200768, 0.5200768]\n",
      "tf auc: [0.75926757, 0.75926757]\n",
      "tf auc: [0.5273004, 0.5273004]\n",
      "tf auc: [0.5347089, 0.5347089]\n",
      "tf auc: [0.5167115, 0.5167115]\n",
      "tf auc: [0.591353, 0.591353]\n",
      "tf auc: [0.5263662, 0.5263662]\n",
      "tf auc: [0.69404685, 0.69404685]\n",
      "tf auc: [0.50514066, 0.50514066]\n",
      "tf auc: [0.68637854, 0.68637854]\n",
      "tf auc: [0.507054, 0.507054]\n",
      "tf auc: [0.5238637, 0.5238637]\n",
      "tf auc: [0.51710933, 0.51710933]\n"
     ]
    }
   ],
   "source": [
    "AUC_List = []\n",
    "y_pred_T = y_pred.T\n",
    "y_test_T = y_test.T\n",
    "    \n",
    "for i in range(50):\n",
    "        \n",
    "    try:\n",
    "        auc, update_op = tf.metrics.auc(y_test_T[i] ,K.round(y_pred_T[i]))\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            print(\"tf auc: {}\".format(sess.run([auc, update_op])))\n",
    "        \n",
    "        \n",
    "        AUC_List.append(auc)\n",
    "        \n",
    "    except:\n",
    "        AUC_List.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC , AUC_List , y = STL_AUC(parallel_model,ADG_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.647678309820368,\n",
       " 0.6292925330279041,\n",
       " 0.6388851455778919,\n",
       " 0.7164604686873104,\n",
       " 0.6813197292833203,\n",
       " 0.7367744805378355,\n",
       " 0.5295770955852077,\n",
       " 0.6348123855492506,\n",
       " 0.5514497619492394,\n",
       " 0.5901453397467135,\n",
       " 0.5498822350119916,\n",
       " 0.6277543583037901,\n",
       " 0.8274742837131315,\n",
       " 0.5794283118571738,\n",
       " 0.5483279041746784,\n",
       " 0.5224743072039797,\n",
       " 0.6200569159083091,\n",
       " 0.721438589422542,\n",
       " 0.5867646209479895,\n",
       " 0.6463665871141342,\n",
       " 0.6057830576851759,\n",
       " 0.539456079115765,\n",
       " 0.545493048183569,\n",
       " 0.5127919902519766,\n",
       " 0.5071131454809313,\n",
       " 0.7794094973789701,\n",
       " 0.6600448819962347,\n",
       " 0.5128818064080185,\n",
       " 0.695522902135402,\n",
       " 0.6355979087466176,\n",
       " 0.5045329024937281,\n",
       " 0.5203454708613685,\n",
       " 0.628895172628173,\n",
       " 0.5478566128039486,\n",
       " 0.5200879850531166,\n",
       " 0.7689491138887922,\n",
       " 0.5867313178596478,\n",
       " 0.5200768105553322,\n",
       " 0.7592675866742956,\n",
       " 0.5273004041213881,\n",
       " 0.5347089737447586,\n",
       " 0.516711456704494,\n",
       " 0.5913530485782358,\n",
       " 0.526366191005635,\n",
       " 0.6940468623320499,\n",
       " 0.5051406803146111,\n",
       " 0.6863785309045494,\n",
       " 0.5070539463345433,\n",
       " 0.523863678276799,\n",
       " 0.5171093011791118]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History = parallel_model.fit_generator(\n",
    "                    generator= ADG_train,\n",
    "                    steps_per_epoch=(num_training_samples // _batchSize),\n",
    "                    epochs= 100,\n",
    "                    verbose=1,\n",
    "                    validation_data= ADG_test,\n",
    "                    validation_steps=(num_validation_samples // _batchSize),\n",
    "                    workers=12, use_multiprocessing=True,\n",
    "                    callbacks = [ early_stopping,time_callback, checkpointer]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_string = parallel_model.to_json()\n",
    "with codecs.open('Audio_CRNN_RE.json','w', encoding = 'utf8') as outfile:\n",
    "    json.dump(json_string,outfile)\n",
    "with codecs.open('Audio_CRNN_RE_History.json','w', encoding = 'utf8') as outfile:\n",
    "    json.dump(History.history,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.load_weights('Audio_CRNN_RE_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC , AUC_List , y = STL_AUC(parallel_model,ADG_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
