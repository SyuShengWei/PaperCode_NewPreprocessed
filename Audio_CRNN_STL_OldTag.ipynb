{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def STL_AUC(model,SDG,y_true):\n",
    "    Skip_Tag = []\n",
    "        \n",
    "    y_pred = model.predict_generator(generator = SDG,\n",
    "                                        workers = 12,\n",
    "                                        use_multiprocessing=True,) # (#data x 50())  # (#data x 50()) \n",
    "    y_pred_out = y_pred.copy()\n",
    "    #print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "    for i in range(len(y_pred)):\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if y_pred[i][j] >= 0.5 : \n",
    "                y_pred[i][j] = 1\n",
    "            else:\n",
    "                y_pred[i][j] = 0\n",
    "    \n",
    "    #print(y_pred.shape,y_true.shape)\n",
    "    \n",
    "    try:\n",
    "        AUC_this_epoch = roc_auc_score(y_true ,y_pred)\n",
    "    except:\n",
    "        AUC_this_epoch = 0\n",
    "    \n",
    "    \n",
    "    AUC_List = []\n",
    "    y_pred_T = y_pred.T\n",
    "    y_true_T = y_true.T\n",
    "    \n",
    "    for i in range(50):\n",
    "        \n",
    "        try:\n",
    "            AUC_List.append( roc_auc_score(y_true_T[i] ,y_pred_T[i]))\n",
    "        except:\n",
    "            AUC_List.append(0)\n",
    "    return AUC_this_epoch,AUC_List,y_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read Data Base\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "uri = \"mongodb://localhost:27017/database\" #mongodb://<user_name>:<user_password>@ds<xxxxxx>.mlab.com:<xxxxx>/<database_name>\n",
    "conn =  MongoClient(host='localhost', port=27017, connect=False)\n",
    "db = conn.PaperData\n",
    "Spectrogram_Collection  =  db.get_collection('MSD_mel1366')\n",
    "#LineCNN_Collection  =  db.get_collection('LineCNNMatrix_100thTag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58487"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spectrogram_Collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Filename_text'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spectrogram_Collection.create_index([(\"Filename\",\"text\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio Para\n",
    "_mel_scale = 96\n",
    "_time_len = 1366\n",
    "_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_num_Tags = 50\n",
    "_epchos = 200\n",
    "_stopEpcho = 10\n",
    "_batchSize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import codecs\n",
    "import numpy as np\n",
    "def read_json(filename):\n",
    "    with codecs.open(filename,'r',encoding = 'utf8') as infile:\n",
    "        return np.array(json.load(infile))\n",
    "    \n",
    "x_train = read_json('New_x_train.json')\n",
    "y_train = read_json('Old_y_train.json')\n",
    "x_test = read_json('New_x_test.json')\n",
    "y_test = read_json('Old_y_test.json')\n",
    "x_val = read_json('New_x_val.json')\n",
    "y_val = read_json('Old_y_val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train) == len(y_train))\n",
    "print(len(x_test) == len(y_test))\n",
    "print(len(x_val) == len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CL_1_kernal = 169\n",
    "_CL_2_kernal = 339\n",
    "_CL_3_kernal = 339\n",
    "_CL_4_kernal = 339\n",
    "_RNN_1_kernal = 169\n",
    "_RNN_2_kernal = 169\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectrogram_Input = Input(name= 'AudioInput',shape=(_mel_scale, _time_len, _channels)) #(None(1), 96, 1292, 1)\n",
    "CL_1 = Conv2D(_CL_1_kernal, kernel_size=(3, 3),padding='same', name = \"CL_1\")(Spectrogram_Input) #(None, 96, 1292, 128) \n",
    "BN_1 = BatchNormalization()(CL_1)\n",
    "AL_1 = ELU()(BN_1)\n",
    "MP_1 = MaxPool2D(pool_size= (2,2), name = \"MPL_1\")(AL_1) #(None, 48, 323, 128)\n",
    "DP_1 = Dropout(0.1)(MP_1)\n",
    "\n",
    "CL_2 = Conv2D(_CL_2_kernal, kernel_size=(3, 3),padding='same', name = \"CL_2\")(DP_1) # (None, 48, 323, 384) \n",
    "BN_2 = BatchNormalization()(CL_2)\n",
    "AL_2 = ELU()(BN_2)\n",
    "MP_2 = MaxPool2D(pool_size= (3,3), name = \"MPL_2\")(AL_2) # (None, 12, 64, 384) \n",
    "DP_2 = Dropout(0.1)(MP_2)\n",
    "\n",
    "CL_3 = Conv2D(_CL_3_kernal, kernel_size=(3, 3),padding='same', name = \"CL_3\")(DP_2) #(None, 12, 64, 768) \n",
    "BN_3 = BatchNormalization()(CL_3)\n",
    "AL_3 = ELU()(BN_3)\n",
    "MP_3 = MaxPool2D(pool_size= (4,4), name = \"MPL_3\")(AL_3) #(None, 4, 8, 768)\n",
    "DP_3 = Dropout(0.1)(MP_3)\n",
    "\n",
    "CL_4 = Conv2D(_CL_4_kernal, kernel_size=(3, 3),padding='same', name = \"CL_4\")(DP_3) #(None, 4, 8, 2048) \n",
    "BN_4 = BatchNormalization()(CL_4)\n",
    "AL_4 = ELU()(BN_4)\n",
    "MP_4 = MaxPool2D(pool_size= (4,4), name = \"MPL_4\")(AL_4)#(None, 1, 1, 2048) \n",
    "DP_4 = Dropout(0.1)(MP_4)\n",
    "\n",
    "AR = Permute((3,2,1))(DP_4)\n",
    "RS = Reshape((14, _CL_2_kernal))(DP_4)\n",
    "\n",
    "GRU_1 = GRU(_RNN_1_kernal, return_sequences=True, name='GRU_1')(RS)\n",
    "GRU_2 = GRU(_RNN_2_kernal, return_sequences=False, name='GRU_2')(GRU_1)\n",
    "\n",
    "#pseudo-model for sheck summary\n",
    "Softmax = Dense(_num_Tags, kernel_initializer='normal',activation='sigmoid')(GRU_2)\n",
    "Audio_model = Model(inputs=Spectrogram_Input, outputs=Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "AudioInput (InputLayer)      (None, 96, 1366, 1)       0         \n",
      "_________________________________________________________________\n",
      "CL_1 (Conv2D)                (None, 96, 1366, 169)     1690      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1366, 169)     676       \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 96, 1366, 169)     0         \n",
      "_________________________________________________________________\n",
      "MPL_1 (MaxPooling2D)         (None, 48, 683, 169)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 683, 169)      0         \n",
      "_________________________________________________________________\n",
      "CL_2 (Conv2D)                (None, 48, 683, 339)      515958    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 683, 339)      1356      \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 48, 683, 339)      0         \n",
      "_________________________________________________________________\n",
      "MPL_2 (MaxPooling2D)         (None, 16, 227, 339)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 227, 339)      0         \n",
      "_________________________________________________________________\n",
      "CL_3 (Conv2D)                (None, 16, 227, 339)      1034628   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 227, 339)      1356      \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 16, 227, 339)      0         \n",
      "_________________________________________________________________\n",
      "MPL_3 (MaxPooling2D)         (None, 4, 56, 339)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 56, 339)        0         \n",
      "_________________________________________________________________\n",
      "CL_4 (Conv2D)                (None, 4, 56, 339)        1034628   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 56, 339)        1356      \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 4, 56, 339)        0         \n",
      "_________________________________________________________________\n",
      "MPL_4 (MaxPooling2D)         (None, 1, 14, 339)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 14, 339)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 14, 339)           0         \n",
      "_________________________________________________________________\n",
      "GRU_1 (GRU)                  (None, 14, 169)           258063    \n",
      "_________________________________________________________________\n",
      "GRU_2 (GRU)                  (None, 169)               171873    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                8500      \n",
      "=================================================================\n",
      "Total params: 3,030,084\n",
      "Trainable params: 3,027,712\n",
      "Non-trainable params: 2,372\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Audio_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "import json\n",
    "import codecs\n",
    "class AudioDataGenerator(Sequence):\n",
    "    #batch size can only be 1\n",
    "    def __init__(self, text_filenames, labels,batch_size):\n",
    "        self.text_filenames, self.labels = text_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.text_filenames)/ (self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Here, you have to imprement what the data looks like in each epcho\n",
    "        filename_List =  self.text_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        #Text_batch_x = [] \n",
    "        Audio_batch_x = []\n",
    "        for filename in filename_List:  \n",
    "            Audio_x = np.array(Spectrogram_Collection.find_one({\"Filename\":filename})['Spectrogram']).reshape((_mel_scale,_time_len,_channels))\n",
    "            Audio_batch_x.append(Audio_x)\n",
    "        y_List = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return np.array(Audio_batch_x), np.array(y_List)\n",
    "    def getitem(self, idx):\n",
    "        #Here, you have to imprement what the data looks like in each epcho\n",
    "        \n",
    "        return self.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADG_train = AudioDataGenerator(x_train, y_train, _batchSize)\n",
    "ADG_test = AudioDataGenerator(x_test[:8480], y_test[:8480], _batchSize) #skip 6 song while training\n",
    "ADG_val = AudioDataGenerator(x_val, y_val, _batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This callback is for binary softmax \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class AUC_callback(Callback):\n",
    "    def __init__(self,y_true,SDG,batchsize):\n",
    "        self.y_true = y_true\n",
    "        self.SDG = SDG\n",
    "        self.step = (len(y_true) // _batchSize)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Skip_Tag = []\n",
    "        \n",
    "        y_pred = self.model.predict_generator(generator = self.SDG,\n",
    "                                         steps = self.step,\n",
    "                                        workers = 12,\n",
    "                                        use_multiprocessing=True,) # (#data x 50()) \n",
    "        y_pred_out = y_pred.copy()\n",
    "    #print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "        for i in range(len(y_pred)):\n",
    "            for j in range(len(y_pred[i])):\n",
    "                if y_pred[i][j] >= 0.5 : \n",
    "                    y_pred[i][j] = 1\n",
    "                else:\n",
    "                    y_pred[i][j] = 0\n",
    "        try:\n",
    "            AUC_this_epoch = roc_auc_score(self.y_true ,y_pred)\n",
    "        except Exception as e:\n",
    "            AUC_this_epoch = 0\n",
    "            print(e)\n",
    "    \n",
    "        AUC_List = []\n",
    "        y_pred_T = y_pred.T\n",
    "        y_true_T = self.y_true .T\n",
    "    \n",
    "        for i in range(50):\n",
    "            try:\n",
    "                AUC_List.append( roc_auc_score(y_true_T[i] ,y_pred_T[i]))\n",
    "            except:\n",
    "                AUC_List.append(0)\n",
    "\n",
    "        logs['AUC_test'] = AUC_this_epoch\n",
    "        \n",
    "        logs['AUC_List'] = AUC_List\n",
    "        \n",
    "        print('AUC_test: %s '% (str(round(AUC_this_epoch,5))))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This callback is for binary softmax \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class AUC_callback_TF(Callback):\n",
    "    def __init__(self,y_true,SDG,batchsize):\n",
    "        self.y_true = y_true\n",
    "        self.SDG = SDG\n",
    "        self.step = (len(y_true) // _batchSize)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        Skip_Tag = []\n",
    "        print(\"[AUC] Start predict...\" ,end = '  ')\n",
    "        y_pred = self.model.predict_generator(generator = self.SDG,\n",
    "                                         steps = self.step,\n",
    "                                        workers = 12,\n",
    "                                        use_multiprocessing=True,) # (#data x 50()) \n",
    "        y_pred_out = y_pred.copy()\n",
    "        print(\"[OK]\")\n",
    "    #print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "        print(\"[AUC] Start calcute auc...\", end = '  ')\n",
    "        for i in range(len(y_pred)):\n",
    "            for j in range(len(y_pred[i])):\n",
    "                if y_pred[i][j] >= 0.5 : \n",
    "                    y_pred[i][j] = 1\n",
    "                else:\n",
    "                    y_pred[i][j] = 0\n",
    "        try:\n",
    "            auc, update_op = tf.metrics.auc(self.y_true ,K.round(y_pred))\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.local_variables_initializer())\n",
    "                AUC_this_epoch= sess.run([auc, update_op])[0]\n",
    "        except Exception as e:\n",
    "            AUC_this_epoch = 0\n",
    "            print(e)\n",
    "        print(\"[Total OK!]\")\n",
    "        \n",
    "        #AUC_List = []\n",
    "        #y_pred_T = y_pred.T\n",
    "        #y_true_T = self.y_true.T\n",
    "    \n",
    "        #for i in range(50):\n",
    "        #    try:\n",
    "        #        auc, update_op = tf.metrics.auc(y_true_T[i] ,K.round(y_pred_T[i]))\n",
    "        #        with tf.Session() as sess:\n",
    "        #            sess.run(tf.local_variables_initializer())\n",
    "        #            AUC_List.append(sess.run([auc, update_op])[0])\n",
    "        #    except Exception as e:\n",
    "        #        AUC_List.append(0)\n",
    "        #        print(e)\n",
    "        #print(\"[Tag OK!]\")\n",
    "        logs['AUC_test'] = AUC_this_epoch\n",
    "        #logs['AUC_List'] = AUC_List\n",
    "        print('AUC_test: %s '% (str(round(AUC_this_epoch,5))))\n",
    "        \n",
    "        \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_AUC = AUC_callback_TF(y_test[:8480],ADG_test,_batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc: [0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "auc, update_op = tf.metrics.auc(np.array([[0,0,1],[1,0,1],[0,1,0]]), np.array([[0,0,0],[0,0,0],[0,0,0]]))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    print(\"tf auc: {}\".format(sess.run([auc, update_op])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='AUC_test',mode='max', patience=_stopEpcho, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import time\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.epoch_time_end = time.time()\n",
    "        self.times.append(self.epoch_time_end - self.epoch_time_start)\n",
    "        logs['Timer'] = self.epoch_time_end - self.epoch_time_start\n",
    "time_callback = TimeHistory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_metrics\n",
    "precision = keras_metrics.precision(label = 1)\n",
    "recall = keras_metrics.recall(label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.quora.com/Why-does-my-convolutional-neural-network-always-produce-the-same-outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"TVT_Audio_CRNN_Old_best.hdf5\",monitor='AUC_test',mode = 'max', verbose=1, save_best_only=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true,  K.round(y_pred))[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples = len(x_train)\n",
    "num_validation_samples = len(x_val)\n",
    "num_test_samples =  len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "928/928 [==============================] - 541s 583ms/step - loss: 0.2953 - auc: 0.5101 - val_loss: 0.3005 - val_auc: 0.5184\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.52453 \n",
      "\n",
      "Epoch 00001: AUC_test improved from -inf to 0.52453, saving model to TVT_Audio_CRNN_best.hdf5\n",
      "Epoch 2/100\n",
      "928/928 [==============================] - 535s 576ms/step - loss: 0.2826 - auc: 0.5206 - val_loss: 0.3222 - val_auc: 0.5221\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.51665 \n",
      "\n",
      "Epoch 00002: AUC_test did not improve from 0.52453\n",
      "Epoch 3/100\n",
      "928/928 [==============================] - 536s 578ms/step - loss: 0.2746 - auc: 0.5242 - val_loss: 0.2959 - val_auc: 0.5264\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.52511 \n",
      "\n",
      "Epoch 00003: AUC_test improved from 0.52453 to 0.52511, saving model to TVT_Audio_CRNN_best.hdf5\n",
      "Epoch 4/100\n",
      "928/928 [==============================] - 536s 578ms/step - loss: 0.2690 - auc: 0.5285 - val_loss: 0.3160 - val_auc: 0.5307\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.5268 \n",
      "\n",
      "Epoch 00004: AUC_test improved from 0.52511 to 0.52680, saving model to TVT_Audio_CRNN_best.hdf5\n",
      "Epoch 5/100\n",
      "928/928 [==============================] - 541s 583ms/step - loss: 0.2651 - auc: 0.5328 - val_loss: 0.2757 - val_auc: 0.5351\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.55178 \n",
      "\n",
      "Epoch 00005: AUC_test improved from 0.52680 to 0.55178, saving model to TVT_Audio_CRNN_best.hdf5\n",
      "Epoch 6/100\n",
      "928/928 [==============================] - 542s 584ms/step - loss: 0.2621 - auc: 0.5373 - val_loss: 0.2763 - val_auc: 0.5391\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.54669 \n",
      "\n",
      "Epoch 00006: AUC_test did not improve from 0.55178\n",
      "Epoch 7/100\n",
      "928/928 [==============================] - 540s 582ms/step - loss: 0.2592 - auc: 0.5410 - val_loss: 0.2785 - val_auc: 0.5430\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.5771 \n",
      "\n",
      "Epoch 00007: AUC_test improved from 0.55178 to 0.57710, saving model to TVT_Audio_CRNN_best.hdf5\n",
      "Epoch 8/100\n",
      "928/928 [==============================] - 540s 582ms/step - loss: 0.2564 - auc: 0.5449 - val_loss: 0.2815 - val_auc: 0.5466\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.5865 \n",
      "\n",
      "Epoch 00008: AUC_test improved from 0.57710 to 0.58650, saving model to TVT_Audio_CRNN_best.hdf5\n",
      "Epoch 9/100\n",
      "928/928 [==============================] - 542s 584ms/step - loss: 0.2544 - auc: 0.5485 - val_loss: 0.2681 - val_auc: 0.5500\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.56721 \n",
      "\n",
      "Epoch 00009: AUC_test did not improve from 0.58650\n",
      "Epoch 10/100\n",
      "928/928 [==============================] - 541s 583ms/step - loss: 0.2521 - auc: 0.5514 - val_loss: 0.2856 - val_auc: 0.5530\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.58402 \n",
      "\n",
      "Epoch 00010: AUC_test did not improve from 0.58650\n",
      "Epoch 11/100\n",
      "928/928 [==============================] - 541s 583ms/step - loss: 0.2492 - auc: 0.5544 - val_loss: 0.2851 - val_auc: 0.5559\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.5904 \n",
      "\n",
      "Epoch 00011: AUC_test improved from 0.58650 to 0.59040, saving model to TVT_Audio_CRNN_best.hdf5\n",
      "Epoch 12/100\n",
      "928/928 [==============================] - 540s 582ms/step - loss: 0.2475 - auc: 0.5574 - val_loss: 0.2688 - val_auc: 0.5587\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.58524 \n",
      "\n",
      "Epoch 00012: AUC_test did not improve from 0.59040\n",
      "Epoch 13/100\n",
      "928/928 [==============================] - 542s 584ms/step - loss: 0.2448 - auc: 0.5601 - val_loss: 0.2827 - val_auc: 0.5612\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.55726 \n",
      "\n",
      "Epoch 00013: AUC_test did not improve from 0.59040\n",
      "Epoch 14/100\n",
      "928/928 [==============================] - 542s 584ms/step - loss: 0.2421 - auc: 0.5624 - val_loss: 0.2744 - val_auc: 0.5636\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.56196 \n",
      "\n",
      "Epoch 00014: AUC_test did not improve from 0.59040\n",
      "Epoch 15/100\n",
      "928/928 [==============================] - 541s 583ms/step - loss: 0.2390 - auc: 0.5648 - val_loss: 0.3029 - val_auc: 0.5660\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.5594 \n",
      "\n",
      "Epoch 00015: AUC_test did not improve from 0.59040\n",
      "Epoch 16/100\n",
      "928/928 [==============================] - 539s 581ms/step - loss: 0.2358 - auc: 0.5673 - val_loss: 0.2951 - val_auc: 0.5687\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.60768 \n",
      "\n",
      "Epoch 00016: AUC_test improved from 0.59040 to 0.60768, saving model to TVT_Audio_CRNN_best.hdf5\n",
      "Epoch 17/100\n",
      "928/928 [==============================] - 538s 580ms/step - loss: 0.2325 - auc: 0.5702 - val_loss: 0.2803 - val_auc: 0.5714\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.57293 \n",
      "\n",
      "Epoch 00017: AUC_test did not improve from 0.60768\n",
      "Epoch 18/100\n",
      "928/928 [==============================] - 541s 583ms/step - loss: 0.2275 - auc: 0.5729 - val_loss: 0.2823 - val_auc: 0.5743\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.60132 \n",
      "\n",
      "Epoch 00018: AUC_test did not improve from 0.60768\n",
      "Epoch 19/100\n",
      "928/928 [==============================] - 539s 580ms/step - loss: 0.2239 - auc: 0.5760 - val_loss: 0.2684 - val_auc: 0.5775\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.59337 \n",
      "\n",
      "Epoch 00019: AUC_test did not improve from 0.60768\n",
      "Epoch 20/100\n",
      "928/928 [==============================] - 539s 580ms/step - loss: 0.2193 - auc: 0.5791 - val_loss: 0.2845 - val_auc: 0.5806\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.56463 \n",
      "\n",
      "Epoch 00020: AUC_test did not improve from 0.60768\n",
      "Epoch 21/100\n",
      "928/928 [==============================] - 537s 579ms/step - loss: 0.2151 - auc: 0.5822 - val_loss: 0.2842 - val_auc: 0.5838\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.58324 \n",
      "\n",
      "Epoch 00021: AUC_test did not improve from 0.60768\n",
      "Epoch 22/100\n",
      "928/928 [==============================] - 537s 579ms/step - loss: 0.2101 - auc: 0.5855 - val_loss: 0.2807 - val_auc: 0.5873\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.6185 \n",
      "\n",
      "Epoch 00022: AUC_test improved from 0.60768 to 0.61850, saving model to TVT_Audio_CRNN_best.hdf5\n",
      "Epoch 23/100\n",
      "928/928 [==============================] - 539s 581ms/step - loss: 0.2061 - auc: 0.5891 - val_loss: 0.2883 - val_auc: 0.5909\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.61079 \n",
      "\n",
      "Epoch 00023: AUC_test did not improve from 0.61850\n",
      "Epoch 24/100\n",
      "928/928 [==============================] - 539s 580ms/step - loss: 0.2027 - auc: 0.5927 - val_loss: 0.2956 - val_auc: 0.5943\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.59012 \n",
      "\n",
      "Epoch 00024: AUC_test did not improve from 0.61850\n",
      "Epoch 25/100\n",
      "928/928 [==============================] - 540s 581ms/step - loss: 0.1994 - auc: 0.5960 - val_loss: 0.2962 - val_auc: 0.5977\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.58055 \n",
      "\n",
      "Epoch 00025: AUC_test did not improve from 0.61850\n",
      "Epoch 26/100\n",
      "928/928 [==============================] - 540s 582ms/step - loss: 0.1958 - auc: 0.5993 - val_loss: 0.2907 - val_auc: 0.6010\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.60554 \n",
      "\n",
      "Epoch 00026: AUC_test did not improve from 0.61850\n",
      "Epoch 27/100\n",
      "928/928 [==============================] - 538s 579ms/step - loss: 0.1922 - auc: 0.6027 - val_loss: 0.2882 - val_auc: 0.6044\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.59859 \n",
      "\n",
      "Epoch 00027: AUC_test did not improve from 0.61850\n",
      "Epoch 28/100\n",
      "928/928 [==============================] - 540s 582ms/step - loss: 0.1896 - auc: 0.6060 - val_loss: 0.2882 - val_auc: 0.6077\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.61794 \n",
      "\n",
      "Epoch 00028: AUC_test did not improve from 0.61850\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 538s 579ms/step - loss: 0.1871 - auc: 0.6093 - val_loss: 0.2957 - val_auc: 0.6109\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.59887 \n",
      "\n",
      "Epoch 00029: AUC_test did not improve from 0.61850\n",
      "Epoch 30/100\n",
      "928/928 [==============================] - 534s 576ms/step - loss: 0.1838 - auc: 0.6125 - val_loss: 0.2919 - val_auc: 0.6140\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.61161 \n",
      "\n",
      "Epoch 00030: AUC_test did not improve from 0.61850\n",
      "Epoch 31/100\n",
      "928/928 [==============================] - 538s 580ms/step - loss: 0.1808 - auc: 0.6156 - val_loss: 0.3019 - val_auc: 0.6171\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.59126 \n",
      "\n",
      "Epoch 00031: AUC_test did not improve from 0.61850\n",
      "Epoch 32/100\n",
      "928/928 [==============================] - 538s 579ms/step - loss: 0.1782 - auc: 0.6187 - val_loss: 0.3068 - val_auc: 0.6202\n",
      "[AUC] Start predict...  [OK]\n",
      "[AUC] Start calcute auc...  [Total OK!]\n",
      "AUC_test: 0.6096 \n",
      "\n",
      "Epoch 00032: AUC_test did not improve from 0.61850\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "#THis may be the final version of CRNN audio !!!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.utils import multi_gpu_model\n",
    "parallel_model = multi_gpu_model(Audio_model, gpus=2)\n",
    "parallel_model.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer='adam',\n",
    "                      metrics=[auc])\n",
    "History = parallel_model.fit_generator(\n",
    "                    generator= ADG_train,\n",
    "                    steps_per_epoch=(num_training_samples // _batchSize),\n",
    "                    epochs= 100,\n",
    "                    verbose=1,\n",
    "                    validation_data= ADG_val,\n",
    "                    validation_steps=(num_validation_samples // _batchSize),\n",
    "                    workers=12, use_multiprocessing=True,\n",
    "                    callbacks = [Test_AUC,early_stopping,time_callback, checkpointer]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(History.history['AUC_test'])):\n",
    "    History.history['AUC_test'][i] = History.history['AUC_test'][i].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_string = parallel_model.to_json()\n",
    "with codecs.open('Audio_CRNN_old.json','w', encoding = 'utf8') as outfile:\n",
    "    json.dump(json_string,outfile)\n",
    "with codecs.open('Audio_CRNN_old_History.json','w', encoding = 'utf8') as outfile:\n",
    "    json.dump(History.history,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.load_weights('TVT_Audio_CRNN_Old_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = parallel_model.predict_generator(ADG_test,workers=12,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8480, 50)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_out = y_pred.copy()\n",
    "#print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if y_pred[i][j] >= 0.5 : \n",
    "            y_pred[i][j] = 1\n",
    "        else:\n",
    "            y_pred[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[8480].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc: [0.61850405, 0.61850405]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    auc, update_op = tf.metrics.auc(y_test[:8480] ,K.round(y_pred))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        print(\"tf auc: {}\".format(sess.run([auc, update_op])))\n",
    "except Exception as e:\n",
    "    AUC_this_epoch = 0\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc: [0.6438254, 0.6438254]\n",
      "tf auc: [0.63034207, 0.63034207]\n",
      "tf auc: [0.6140687, 0.6140687]\n",
      "tf auc: [0.73055744, 0.73055744]\n",
      "tf auc: [0.6595194, 0.6595194]\n",
      "tf auc: [0.73368037, 0.73368037]\n",
      "tf auc: [0.5192147, 0.5192147]\n",
      "tf auc: [0.5356427, 0.5356427]\n",
      "tf auc: [0.6223979, 0.6223979]\n",
      "tf auc: [0.5321041, 0.5321041]\n",
      "tf auc: [0.5726798, 0.5726798]\n",
      "tf auc: [0.53070086, 0.53070086]\n",
      "tf auc: [0.56584775, 0.56584775]\n",
      "tf auc: [0.6273218, 0.6273218]\n",
      "tf auc: [0.7119799, 0.7119799]\n",
      "tf auc: [0.55210257, 0.55210257]\n",
      "tf auc: [0.5234359, 0.5234359]\n",
      "tf auc: [0.50505906, 0.50505906]\n",
      "tf auc: [0.5936634, 0.5936634]\n",
      "tf auc: [0.61326844, 0.61326844]\n",
      "tf auc: [0.6915113, 0.6915113]\n",
      "tf auc: [0.616504, 0.616504]\n",
      "tf auc: [0.57522607, 0.57522607]\n",
      "tf auc: [0.6490817, 0.6490817]\n",
      "tf auc: [0.55495, 0.55495]\n",
      "tf auc: [0.50427324, 0.50427324]\n",
      "tf auc: [0.5013928, 0.5013928]\n",
      "tf auc: [0.53734064, 0.53734064]\n",
      "tf auc: [0.5053851, 0.5053851]\n",
      "tf auc: [0.5, 0.5]\n",
      "tf auc: [0.71312386, 0.71312386]\n",
      "tf auc: [0.6096273, 0.6096273]\n",
      "tf auc: [0.49993426, 0.49993426]\n",
      "tf auc: [0.6379583, 0.6379583]\n",
      "tf auc: [0.5737235, 0.5737235]\n",
      "tf auc: [0.50155705, 0.50155705]\n",
      "tf auc: [0.5001646, 0.5001646]\n",
      "tf auc: [0.51644546, 0.51644546]\n",
      "tf auc: [0.6281546, 0.6281546]\n",
      "tf auc: [0.5161187, 0.5161187]\n",
      "tf auc: [0.50009626, 0.50009626]\n",
      "tf auc: [0.58277535, 0.58277535]\n",
      "tf auc: [0.5074978, 0.5074978]\n",
      "tf auc: [0.7357277, 0.7357277]\n",
      "tf auc: [0.5350109, 0.5350109]\n",
      "tf auc: [0.51537246, 0.51537246]\n",
      "tf auc: [0.63002145, 0.63002145]\n",
      "tf auc: [0.5246097, 0.5246097]\n",
      "tf auc: [0.5323313, 0.5323313]\n",
      "tf auc: [0.5117103, 0.5117103]\n"
     ]
    }
   ],
   "source": [
    "AUC_List = []\n",
    "y_pred_T = y_pred.T\n",
    "y_test_T = y_test[:8480].T\n",
    "    \n",
    "for i in range(50):\n",
    "        \n",
    "    try:\n",
    "        auc, update_op = tf.metrics.auc(y_test_T[i] ,K.round(y_pred_T[i]))\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            print(\"tf auc: {}\".format(sess.run([auc, update_op])))\n",
    "        AUC_List.append(auc)\n",
    "        \n",
    "    except:\n",
    "        AUC_List.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
